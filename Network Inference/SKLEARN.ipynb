{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>848</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1342</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1802</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1     2    3    4    5    6    7     8    9    ...  176  177  178  \\\n",
       "0  289    0     0    0  579    0    0    0   848  416  ...    0    0    0   \n",
       "1    0    0  1342  243    0    0    0  350     0  238  ...    0    0    0   \n",
       "2    0  402     0  494    0    0    0    0  1802  472  ...    0    0    0   \n",
       "3    0  309  1104    0  136    0    0    0   597    0  ...    0    0    0   \n",
       "4    0  148     0    0  740    0    0  460     0  132  ...    0    0    0   \n",
       "\n",
       "   179  180  181  182  183  184  185  \n",
       "0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 186)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-36]\n",
    "y=df.iloc[:,-36:]\n",
    "y=y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=[]\n",
    "for i in y:\n",
    "    z.append(str(i))\n",
    "le=preprocessing.LabelEncoder()\n",
    "y=le.fit_transform(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=100, random_state=2,n_estimators=2500,criterion='gini')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "prediction=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  77.61194029850746\n",
      "MAE: 1.5024875621890548\n",
      "MSE: 20.47761194029851\n",
      "RMSE: 4.52521954608818\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY: ', metrics.accuracy_score(prediction, y_test) * 100)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.30      0.32        10\n",
      "           1       0.45      0.50      0.48        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00        10\n",
      "           6       0.90      0.90      0.90        10\n",
      "           7       0.80      0.40      0.53        10\n",
      "           8       0.60      0.90      0.72        10\n",
      "           9       0.67      0.80      0.73        10\n",
      "          10       0.67      0.80      0.73        10\n",
      "          11       1.00      0.90      0.95        10\n",
      "          12       1.00      1.00      1.00        10\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      1.00      1.00        10\n",
      "          15       0.91      1.00      0.95        10\n",
      "          16       1.00      0.50      0.67        10\n",
      "          17       0.30      0.30      0.30        10\n",
      "          18       0.57      0.80      0.67        10\n",
      "          19       0.91      1.00      0.95        10\n",
      "          20       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.78       201\n",
      "   macro avg       0.75      0.74      0.74       201\n",
      "weighted avg       0.79      0.78      0.77       201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnav/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"a.csv\",header=None)\n",
    "df1=df1.iloc[1:]\n",
    "df1=df1.loc[~(df1=='0').all(axis=1)]\n",
    "#prediction=clf.predict_proba(df1[200:250].to_numpy().flatten().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "prob=[]\n",
    "l=math.floor(len(df1))\n",
    "for i in range(0,l,50):\n",
    "    if(i+50<=l):\n",
    "        prediction=clf.predict_proba(df1[i:i+50].to_numpy().flatten().reshape(1,-1))\n",
    "        score=score+[prediction.tolist()[0].index(max(prediction.tolist()[0]))]\n",
    "        prob=prob+[max(prediction.tolist()[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 20, 15, 15, 15]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2132, 0.1276, 0.2444, 0.618, 0.5508]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=score[prob.index(max(prob))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]'],\n",
       "      dtype='<U73')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(X_train, y_train)\n",
    "prediction=neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  44.27860696517413\n",
      "MAE: 4.039800995024875\n",
      "MSE: 48.398009950248756\n",
      "RMSE: 6.9568678261304315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.70      0.47        10\n",
      "           1       0.20      0.10      0.13        10\n",
      "           2       0.77      1.00      0.87        10\n",
      "           3       0.91      1.00      0.95        10\n",
      "           4       0.62      1.00      0.77        10\n",
      "           5       0.36      0.80      0.50        10\n",
      "           6       0.25      0.30      0.27        10\n",
      "           7       0.30      0.70      0.42        10\n",
      "           8       0.14      0.10      0.12        10\n",
      "           9       0.27      0.30      0.29        10\n",
      "          10       0.35      0.80      0.48        10\n",
      "          11       1.00      0.10      0.18        10\n",
      "          12       0.73      0.80      0.76        10\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00        10\n",
      "          15       0.53      1.00      0.69        10\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.40      0.20      0.27        10\n",
      "          18       0.00      0.00      0.00        10\n",
      "          19       0.00      0.00      0.00        10\n",
      "          20       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.44       201\n",
      "   macro avg       0.34      0.42      0.34       201\n",
      "weighted avg       0.36      0.44      0.36       201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY: ', metrics.accuracy_score(prediction, y_test) * 100)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  67.16417910447761\n",
      "MAE: 1.7213930348258706\n",
      "MSE: 22.0\n",
      "RMSE: 4.69041575982343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.20      0.20        10\n",
      "           1       0.38      0.50      0.43        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00        10\n",
      "           6       1.00      0.50      0.67        10\n",
      "           7       0.00      0.00      0.00        10\n",
      "           8       0.40      1.00      0.57        10\n",
      "           9       1.00      0.40      0.57        10\n",
      "          10       0.57      0.80      0.67        10\n",
      "          11       0.71      1.00      0.83        10\n",
      "          12       1.00      1.00      1.00        10\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      1.00      1.00        10\n",
      "          15       1.00      1.00      1.00        10\n",
      "          16       0.67      0.60      0.63        10\n",
      "          17       0.14      0.10      0.12        10\n",
      "          18       0.42      0.50      0.45        10\n",
      "          19       0.67      0.60      0.63        10\n",
      "          20       0.33      0.30      0.32        10\n",
      "\n",
      "    accuracy                           0.67       201\n",
      "   macro avg       0.64      0.64      0.62       201\n",
      "weighted avg       0.67      0.67      0.65       201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY: ', metrics.accuracy_score(prediction, y_test) * 100)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = SVC(probability=True)\n",
    "clf2 = RandomForestClassifier(n_estimators=2500, random_state=1)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=2)\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "eclf.fit(X_train, y_train)\n",
    "prediction=eclf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  61.69154228855721\n",
      "MAE: 2.63681592039801\n",
      "MSE: 32.90547263681592\n",
      "RMSE: 5.73632919529693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40        10\n",
      "           1       0.50      0.40      0.44        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       0.91      1.00      0.95        10\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       0.67      1.00      0.80        10\n",
      "           6       0.86      0.60      0.71        10\n",
      "           7       0.45      0.50      0.48        10\n",
      "           8       0.31      0.40      0.35        10\n",
      "           9       0.40      0.20      0.27        10\n",
      "          10       0.32      0.80      0.46        10\n",
      "          11       0.83      0.50      0.62        10\n",
      "          12       0.83      1.00      0.91        10\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      0.80      0.89        10\n",
      "          15       0.59      1.00      0.74        10\n",
      "          16       1.00      0.30      0.46        10\n",
      "          17       0.33      0.40      0.36        10\n",
      "          18       0.75      0.60      0.67        10\n",
      "          19       0.75      0.30      0.43        10\n",
      "          20       0.50      0.20      0.29        10\n",
      "\n",
      "    accuracy                           0.62       201\n",
      "   macro avg       0.63      0.59      0.58       201\n",
      "weighted avg       0.66      0.62      0.60       201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY: ', metrics.accuracy_score(prediction, y_test) * 100)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
